<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code on Timoka&#39;s Blog</title>
    <link>https://Timoka47.github.io/cn/categories/code/</link>
    <description>Recent content in Code on Timoka&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 07 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://Timoka47.github.io/cn/categories/code/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SETR</title>
      <link>https://Timoka47.github.io/cn/posts/setrcode/</link>
      <pubDate>Sat, 07 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/setrcode/</guid>
      <description>Decoder naive class SETR_Naive(SegmentationTransformer): def __init__( self, img_dim, patch_dim, num_channels, num_classes, embedding_dim, num_heads, num_layers, hidden_dim, dropout_rate=0.0, attn_dropout_rate=0.0, conv_patch_representation=False, positional_encoding_type=&amp;#34;learned&amp;#34;, ): super(SETR_Naive, self).__init__( img_dim=img_dim, patch_dim=patch_dim, num_channels=num_channels, embedding_dim=embedding_dim, num_heads=num_heads, num_layers=num_layers, hidden_dim=hidden_dim, dropout_rate=dropout_rate, attn_dropout_rate=attn_dropout_rate, conv_patch_representation=conv_patch_representation, positional_encoding_type=positional_encoding_type, ) self.num_classes = num_classes self._init_decode() #两个（1×1卷积+BN+ReLU）+上采样 def _init_decode(self): self.conv1 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=self._get_padding(&amp;#39;VALID&amp;#39;, (1, 1),), ) self.bn1 = nn.BatchNorm2d(self.embedding_dim) self.act1 = nn.ReLU() self.conv2 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.num_classes, kernel_size=1, stride=1, padding=self._get_padding(&amp;#39;VALID&amp;#39;, (1, 1),), ) self.upsample = nn.</description>
    </item>
    
    <item>
      <title>DeepLab系列</title>
      <link>https://Timoka47.github.io/cn/posts/deeplab%E7%B3%BB%E5%88%97code/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/deeplab%E7%B3%BB%E5%88%97code/</guid>
      <description>V1 import torch import torch.nn as nn import torch.nn.functional as F # 使用torch的nn模块中BatchNorm/在encoding文件中定义的BatchNorm try: from encoding.nn import SyncBatchNorm _BATCH_NORM = SyncBatchNorm except: _BATCH_NORM = nn.BatchNorm2d _BOTTLENECK_EXPANSION = 4 #卷积+BN+非线性激活 class _ConvBnReLU(nn.Sequential): BATCH_NORM = _BATCH_NORM def __init__(self, in_ch, out_ch, kernel_size, stride, padding, dilation, relu=True): super(_ConvBnReLU, self).__init__() self.add_module( &amp;#34;conv&amp;#34;,nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, dilation, bias=False), ) self.add_module(&amp;#34;bn&amp;#34;, _BATCH_NORM(out_ch, eps=1e-5, momentum=0.999)) if relu: self.add_module(&amp;#34;relu&amp;#34;, nn.ReLU()) #ResNet的Bottleneck #1×1卷积降维+3×3卷积+1×1卷积升维（shortcut） class _Bottleneck(nn.Module): def __init__(self, in_ch, out_ch, stride, dilation, downsample): super(_Bottleneck, self).</description>
    </item>
    
    <item>
      <title>U-Net</title>
      <link>https://Timoka47.github.io/cn/posts/u-netcode/</link>
      <pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/u-netcode/</guid>
      <description>import torch import torch.nn as nn import torch.nn.functional as F #下采样卷积block（3×3卷积+3×3卷积） class UNetConvBlock(nn.Module): def __init__(self, in_chans, out_chans, padding, batch_norm): super(UNetConvBlock, self).__init__() block=[] block.append(nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=int(padding)) block.append(nn.ReLU()) if batch_norm : block.append(nn.BatchNorm2d(out_chans)) block.append(nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=int(padding)) block.append(nn.ReLU()) if batch_norm: block.append(nn.BatchNorm2d(out_chans)) self.block = nn.Sequential(*block) def forward(self, x): out = self.block(x) return out #上采样block class UNetUpBlock(nn.Module): def __init__(self, in_chans, out_chans, up_mode, padding, batch_norm): super(UNetUpBlock, self).__init__() #转置卷积法 if up_mode == &amp;#39;upconv&amp;#39;: self.up = nn.ConvTransposed2d(in_chans, out_chans, kernel_size=2, stride=2) #线性差值法 elif up_mode==&amp;#39;upsample&amp;#39;: self.</description>
    </item>
    
    <item>
      <title>FCN</title>
      <link>https://Timoka47.github.io/cn/posts/fcncode/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/fcncode/</guid>
      <description>class FCNs(nn.Module): def __init__(self, num_classes, backbone=&amp;#34;vgg&amp;#34;): super(FCNs, self).__init__() self.num_classes = num_classes #VGG为提取特征的网络 if backbone == &amp;#34;vgg&amp;#34;: self.features = VGG() #转置卷积(输入通道数，输出通道数，卷积核大小，步长，零填充将添加到输入中每个维度的两侧，在输出形状的每个尺寸的一侧添加的附加大小) #每次上采样2倍，共上采样5次 # deconv1 1/16 self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, output_padding=1) self.bn1 = nn.BatchNorm2d(512) self.relu1 = nn.ReLU() # deconv1 1/8 self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1) self.bn2 = nn.BatchNorm2d(256) self.relu2 = nn.ReLU() # deconv1 1/4 self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1) self.bn3 = nn.BatchNorm2d(128) self.relu3 = nn.</description>
    </item>
    
    <item>
      <title>GoogleNet</title>
      <link>https://Timoka47.github.io/cn/posts/googlenetcode/</link>
      <pubDate>Wed, 30 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/googlenetcode/</guid>
      <description>GoogLeNet获得了2014年ILSVRC比赛分类任务的冠军，其利用Inception模块，在加深网络深度的同时，减少了参数量，从而减少计算资源的利用。
实现 基于pytorch实现的代码如下：
import torch import torch.nn as nn import torch.nn.functional as F #卷积+BN+ReLu class BasicConv2d(nn.Module): def __init__(self, in_channels, out_channals, **kwargs): super(BasicConv2d, self).__init__() self.conv = nn.Conv2d(in_channels, out_channals, **kwargs) self.bn = nn.BatchNorm2d(out_channals) def forward(self, x): x = self.conv(x) x = self.bn(x) return F.relu(x) # Inception模块 class Inception(nn.Module): #（输入通道数，1×1卷积的输出通道数，3×3卷积的降维通道数，3×3卷积的输出通道数， #5×5卷积的降维通道数，5×5卷积的输出通道数，池化通道数） def __init__(self, in_planes,n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes): super(Inception, self).__init__() # 1x1 conv branch self.b1 = BasicConv2d(in_planes, n1x1, kernel_size=1) # 1x1 conv -&amp;gt; 3x3 conv branch self.</description>
    </item>
    
    <item>
      <title>VGG</title>
      <link>https://Timoka47.github.io/cn/posts/vggcode/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/vggcode/</guid>
      <description>VGG
实现 基于pytorch实现的代码如下：
import torch.nn as nn import torch.nn.functional as F from torchsummary import summary class VGG(nn.Module): &amp;#34;&amp;#34;&amp;#34; VGG builder &amp;#34;&amp;#34;&amp;#34; def __init__(self, arch: object, num_classes=1000) -&amp;gt; object: super(VGG, self).__init__() self.in_channels = 3 self.conv3_64 = self.__make_layer(64, arch[0]) self.conv3_128 = self.__make_layer(128, arch[1]) self.conv3_256 = self.__make_layer(256, arch[2]) self.conv3_512a = self.__make_layer(512, arch[3]) self.conv3_512b = self.__make_layer(512, arch[4]) self.fc1 = nn.Linear(7*7*512, 4096) self.bn1 = nn.BatchNorm1d(4096) self.bn2 = nn.BatchNorm1d(4096) self.fc2 = nn.Linear(4096, 4096) self.fc3 = nn.Linear(4096, num_classes) def __make_layer(self, channels, num): layers = [] for i in range(num): layers.</description>
    </item>
    
    <item>
      <title>AlexNet</title>
      <link>https://Timoka47.github.io/cn/posts/alexnetcode/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/alexnetcode/</guid>
      <description>AlexNet在在2012年的ImageNet竞赛中取得了冠军，作为第一个深度卷积网络在该比赛中获得如此好的成绩，AlexNet证实了深度卷积网络的潜力，并引起了研究者们的极大热情。 AlexNet共包含8层，其中前5层为卷积层，后三层为全连接层，最后一个全连接层的输出是1000维，输入softmax产生最终的输出：1000类的标签分布。
实现 基于pytorch实现的代码如下：
import torch from torch import nn from d2l import torch as d2l net = nn.Sequential( nn.Conv2d(1,96,kernel_size=11,stride=4,padding=1),nn.ReLU(), nn.MaxPool2d(kernel_size=3,stride=2), nn.Conv2d(96,256,kernel_size=5,padding=2),nn.ReLU(), nn.MaxPool2d(kernel_size=3,stride=2), nn.Conv2d(256,384,kernel_size=3,padding=1),nn.ReLU(), nn.Conv2d(384,384,kernel_size=3,padding=1),nn.ReLU(), nn.Conv2d(384,256,kernel_size=3,padding=1),nn.ReLU(), nn.MaxPool2d(kernel_size=3,stride=2),nn.Flatten(), nn.Linear(6400,4096),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(4096,4096),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(4096,10)) X = torch.randn(1,1,224,224) for layer in net: X=layer(X) print(layer.__class__.__name__,&amp;#39;output shape:\t&amp;#39;,X.shape) batch_size=128 train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size,resize=224) def evaluate_accuracy_gpu(net,data_iter,device=None): if isinstance(net, nn.Module): net.eval() if not device: device = next(iter(net.parameters())).device metric = d2l.Accumulator(2) with torch.no_grad(): for X,y in data_iter: if isinstance(X,list): X=(x.to(device) for x in X) else: X=X.</description>
    </item>
    
    <item>
      <title>LeNet</title>
      <link>https://Timoka47.github.io/cn/posts/lenetcode/</link>
      <pubDate>Sun, 26 Dec 2021 20:58:21 +0800</pubDate>
      
      <guid>https://Timoka47.github.io/cn/posts/lenetcode/</guid>
      <description>LeNet是很简单的一个经典卷积神经网络，主要用于手写数字识别，所以是一个多分类任务，并且是十个类别。
实现 基于pytorch实现的代码如下：
import torch from torch import nn from d2l import torch as d2l class Reshape(torch.nn.Module): def forward(self,x): return x.view(-1,1,28,28) net = torch.nn.Sequential( Reshape(),nn.Conv2d(1,6,kernel_size=5,padding=2),nn.Sigmoid(), nn.AvgPool2d(kernel_size=2,stride=2), nn.Conv2d(6,16,kernel_size=5),nn.Sigmoid(), nn.AvgPool2d(kernel_size=2,stride=2),nn.Flatten(), nn.Linear(16*5*5,120),nn.Sigmoid(), nn.Linear(120,84),nn.Sigmoid(), nn.Linear(84,10)) X = torch.rand(size=(1,1,28,28),dtype=torch.float32) for layer in net: X = layer(X) print(layer.__class__.__name__,&amp;#39;output shape：\t&amp;#39;,X.shape) batch_size=256 train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size) def evaluate_accuracy_gpu(net,data_iter,device=None): if isinstance(net, nn.Module): net.eval() if not device: device = next(iter(net.parameters())).device metric = d2l.Accumulator(2) with torch.no_grad(): for X,y in data_iter: if isinstance(X,list): X=(x.</description>
    </item>
    
  </channel>
</rss>
