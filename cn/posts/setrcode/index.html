<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.85.0" />
  <script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
  <link href="https://cdn.bootcss.com/highlight.js/8.0/styles/Googlecode.min.css" rel="stylesheet">
  <script src="https://cdn.bootcss.com/highlight.js/8.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="Timoka 47" />
  <meta property="og:url" content="https://Timoka47.github.io/cn/posts/setrcode/" />
  <link rel="canonical" href="https://Timoka47.github.io/cn/posts/setrcode/" /><link rel="alternate" type="application/atom+xml" href="https://Timoka47.github.ioindex.xml" title="Timoka&#39;s Blog">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/Timoka47.github.io"
      },
      "articleSection" : "posts",
      "name" : "SETR",
      "headline" : "SETR",
      "description" : "Decoder naive class SETR_Naive(SegmentationTransformer): def __init__( self, img_dim, patch_dim, num_channels, num_classes, embedding_dim, num_heads, num_layers, hidden_dim, dropout_rate=0.0, attn_dropout_rate=0.0, conv_patch_representation=False, positional_encoding_type=\u0026#34;learned\u0026#34;, ): super(SETR_Naive, self).__init__( img_dim=img_dim, patch_dim=patch_dim, num_channels=num_channels, embedding_dim=embedding_dim, num_heads=num_heads, num_layers=num_layers, hidden_dim=hidden_dim, dropout_rate=dropout_rate, attn_dropout_rate=attn_dropout_rate, conv_patch_representation=conv_patch_representation, positional_encoding_type=positional_encoding_type, ) self.num_classes = num_classes self._init_decode() #两个（1×1卷积\u002bBN\u002bReLU）\u002b上采样 def _init_decode(self): self.conv1 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=self._get_padding(\u0026#39;VALID\u0026#39;, (1, 1),), ) self.bn1 = nn.BatchNorm2d(self.embedding_dim) self.act1 = nn.ReLU() self.conv2 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.num_classes, kernel_size=1, stride=1, padding=self._get_padding(\u0026#39;VALID\u0026#39;, (1, 1),), ) self.upsample = nn.",
      "inLanguage" : "en-US",
      "author" : "Timoka 47",
      "creator" : "Timoka 47",
      "publisher": "Timoka 47",
      "accountablePerson" : "Timoka 47",
      "copyrightHolder" : "Timoka 47",
      "copyrightYear" : "2022",
      "datePublished": "2022-05-07 00:00:00 \u002b0000 UTC",
      "dateModified" : "2022-05-07 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/Timoka47.github.io\/cn\/posts\/setrcode\/",
      "keywords" : [  ]
  }
</script>
<title>SETR</title>
  <meta property="og:title" content="SETR" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="Decoder naive class SETR_Naive(SegmentationTransformer): def __init__( self, img_dim, patch_dim, num_channels, num_classes, embedding_dim, num_heads, num_layers, hidden_dim, dropout_rate=0.0, attn_dropout_rate=0.0, conv_patch_representation=False, positional_encoding_type=&amp;#34;learned&amp;#34;, ): super(SETR_Naive, self).__init__( img_dim=img_dim, patch_dim=patch_dim, num_channels=num_channels, embedding_dim=embedding_dim, num_heads=num_heads, num_layers=num_layers, hidden_dim=hidden_dim, dropout_rate=dropout_rate, attn_dropout_rate=attn_dropout_rate, conv_patch_representation=conv_patch_representation, positional_encoding_type=positional_encoding_type, ) self.num_classes = num_classes self._init_decode() #两个（1×1卷积&#43;BN&#43;ReLU）&#43;上采样 def _init_decode(self): self.conv1 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=self._get_padding(&amp;#39;VALID&amp;#39;, (1, 1),), ) self.bn1 = nn.BatchNorm2d(self.embedding_dim) self.act1 = nn.ReLU() self.conv2 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.num_classes, kernel_size=1, stride=1, padding=self._get_padding(&amp;#39;VALID&amp;#39;, (1, 1),), ) self.upsample = nn." />
  <meta name="description" content="Decoder naive class SETR_Naive(SegmentationTransformer): def __init__( self, img_dim, patch_dim, num_channels, num_classes, embedding_dim, num_heads, num_layers, hidden_dim, dropout_rate=0.0, attn_dropout_rate=0.0, conv_patch_representation=False, positional_encoding_type=&amp;#34;learned&amp;#34;, ): super(SETR_Naive, self).__init__( img_dim=img_dim, patch_dim=patch_dim, num_channels=num_channels, embedding_dim=embedding_dim, num_heads=num_heads, num_layers=num_layers, hidden_dim=hidden_dim, dropout_rate=dropout_rate, attn_dropout_rate=attn_dropout_rate, conv_patch_representation=conv_patch_representation, positional_encoding_type=positional_encoding_type, ) self.num_classes = num_classes self._init_decode() #两个（1×1卷积&#43;BN&#43;ReLU）&#43;上采样 def _init_decode(self): self.conv1 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=self._get_padding(&amp;#39;VALID&amp;#39;, (1, 1),), ) self.bn1 = nn.BatchNorm2d(self.embedding_dim) self.act1 = nn.ReLU() self.conv2 = nn.Conv2d( in_channels=self.embedding_dim, out_channels=self.num_classes, kernel_size=1, stride=1, padding=self._get_padding(&amp;#39;VALID&amp;#39;, (1, 1),), ) self.upsample = nn." />
  <meta property="og:locale" content="en-us" />

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="Timoka&#39;s Blog">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  
</head>


<body>
  <article class="post Chinese" id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/cn/"
      >Timoka 47</a
    >
  </div>
  <div class="header-subtitle"></div>
</header>
<div class="row end-md center-xs header-items">
  
  <div class="header-item">
    <a href="/index.xml" target="_blank">RSS</a>
  </div>
  
  <div class="header-item">
    <a href="https://Timoka47.github.io" target="_blank">About</a>
  </div>
  
</div>
<div class="row end-xs">
   
  <div class="lang-switch col-xs-3 col-xs-offset-9">
    <a href="/en/">English</a>
  </div>
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">SETR</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2022-05-07 00:00:00 UTC">
                07 May 2022
              </time>
              
            </div>
            <div class="col-xs-6">
              
              <div class="post-author">
                <a target="_blank" href="https://Timoka47.github.io/">@Timoka 47</a>
              </div>
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <h2 id="decoder">Decoder</h2>
<h3 id="naive">naive</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SETR_Naive</span>(SegmentationTransformer):
    <span style="color:#66d9ef">def</span> __init__(
        self,
        img_dim,
        patch_dim,
        num_channels,
        num_classes,
        embedding_dim,
        num_heads,
        num_layers,
        hidden_dim,
        dropout_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>,
        attn_dropout_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>,
        conv_patch_representation<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
        positional_encoding_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;learned&#34;</span>,
    ):
        super(SETR_Naive, self)<span style="color:#f92672">.</span>__init__(
            img_dim<span style="color:#f92672">=</span>img_dim,
            patch_dim<span style="color:#f92672">=</span>patch_dim,
            num_channels<span style="color:#f92672">=</span>num_channels,
            embedding_dim<span style="color:#f92672">=</span>embedding_dim,
            num_heads<span style="color:#f92672">=</span>num_heads,
            num_layers<span style="color:#f92672">=</span>num_layers,
            hidden_dim<span style="color:#f92672">=</span>hidden_dim,
            dropout_rate<span style="color:#f92672">=</span>dropout_rate,
            attn_dropout_rate<span style="color:#f92672">=</span>attn_dropout_rate,
            conv_patch_representation<span style="color:#f92672">=</span>conv_patch_representation,
            positional_encoding_type<span style="color:#f92672">=</span>positional_encoding_type,
        )

        self<span style="color:#f92672">.</span>num_classes <span style="color:#f92672">=</span> num_classes
        self<span style="color:#f92672">.</span>_init_decode()

    <span style="color:#75715e">#两个（1×1卷积+BN+ReLU）+上采样</span>
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_init_decode</span>(self):
        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(
            in_channels<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_dim,
            out_channels<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_dim,
            kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
            stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
            padding<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>_get_padding(<span style="color:#e6db74">&#39;VALID&#39;</span>, (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),),
        )
        self<span style="color:#f92672">.</span>bn1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(self<span style="color:#f92672">.</span>embedding_dim)
        self<span style="color:#f92672">.</span>act1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU()
        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(
            in_channels<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>embedding_dim,
            out_channels<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>num_classes,
            kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
            stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
            padding<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>_get_padding(<span style="color:#e6db74">&#39;VALID&#39;</span>, (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),),
        )
        self<span style="color:#f92672">.</span>upsample <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Upsample(
            scale_factor<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>patch_dim, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bilinear&#39;</span>
        )

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">decode</span>(self, x, intmd_x, intmd_layers<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_reshape_output(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv1(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn1(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>act1(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv2(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>upsample(x)
        <span style="color:#66d9ef">return</span> x
</code></pre></div><h3 id="pup">PUP</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SETR_PUP</span>(SegmentationTransformer):
    <span style="color:#66d9ef">def</span> __init__(self,img_dim,patch_dim,num_channels,num_classes,embedding_dim,num_heads,num_layers,hidden_dim,
        dropout_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>,attn_dropout_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>,conv_patch_representation<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,positional_encoding_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;learned&#34;</span>,):
        
        super(SETR_PUP, self)<span style="color:#f92672">.</span>__init__(img_dim<span style="color:#f92672">=</span>img_dim,patch_dim<span style="color:#f92672">=</span>patch_dim,num_channels<span style="color:#f92672">=</span>num_channels,embedding_dim<span style="color:#f92672">=</span>embedding_dim,
            num_heads<span style="color:#f92672">=</span>num_heads,num_layers<span style="color:#f92672">=</span>num_layers,hidden_dim<span style="color:#f92672">=</span>hidden_dim,dropout_rate<span style="color:#f92672">=</span>dropout_rate,attn_dropout_rate<span style="color:#f92672">=</span>attn_dropout_rate,
            conv_patch_representation<span style="color:#f92672">=</span>conv_patch_representation,positional_encoding_type<span style="color:#f92672">=</span>positional_encoding_type,)

        self<span style="color:#f92672">.</span>num_classes <span style="color:#f92672">=</span> num_classes
        self<span style="color:#f92672">.</span>_init_decode()

    <span style="color:#75715e">#四次（卷积+上采样）：一次上采样2倍</span>
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_init_decode</span>(self):
        extra_in_channels <span style="color:#f92672">=</span> int(self<span style="color:#f92672">.</span>embedding_dim <span style="color:#f92672">/</span> <span style="color:#ae81ff">4</span>)
        in_channels <span style="color:#f92672">=</span> [
            self<span style="color:#f92672">.</span>embedding_dim,
            extra_in_channels,
            extra_in_channels,
            extra_in_channels,
            extra_in_channels,
        ]
        out_channels <span style="color:#f92672">=</span> [
            extra_in_channels,
            extra_in_channels,
            extra_in_channels,
            extra_in_channels,
            self<span style="color:#f92672">.</span>num_classes,
        ]

        modules <span style="color:#f92672">=</span> []
        <span style="color:#66d9ef">for</span> i, (in_channel, out_channel) <span style="color:#f92672">in</span> enumerate(zip(in_channels, out_channels)):
            modules<span style="color:#f92672">.</span>append(nn<span style="color:#f92672">.</span>Conv2d(
                in_channels<span style="color:#f92672">=</span>in_channel,
                out_channels<span style="color:#f92672">=</span>out_channel,
                kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                padding<span style="color:#f92672">=</span>self<span style="color:#f92672">.</span>_get_padding(<span style="color:#e6db74">&#39;VALID&#39;</span>, (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),),
                )
            )
            <span style="color:#75715e">#进行4次上采样</span>
            <span style="color:#66d9ef">if</span> i <span style="color:#f92672">!=</span> <span style="color:#ae81ff">4</span>:
                modules<span style="color:#f92672">.</span>append(nn<span style="color:#f92672">.</span>Upsample(scale_factor<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bilinear&#39;</span>))
        self<span style="color:#f92672">.</span>decode_net <span style="color:#f92672">=</span> IntermediateSequential(<span style="color:#f92672">*</span>modules, return_intermediate<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">decode</span>(self, x, intmd_x, intmd_layers<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_reshape_output(x)
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>decode_net(x)
        <span style="color:#66d9ef">return</span> x
</code></pre></div><h3 id="mla">MLA</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SETR_MLA</span>(nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self, in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">1024</span>, mla_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>, norm_cfg<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
        super(Conv_MLA, self)<span style="color:#f92672">.</span>__init__()
        <span style="color:#75715e">#每层特征经过1×1卷积</span>
        self<span style="color:#f92672">.</span>mla_p2_1x1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(
            in_channels, mla_channels, <span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p3_1x1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(
            in_channels, mla_channels, <span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p4_1x1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(
            in_channels, mla_channels, <span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p5_1x1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(
            in_channels, mla_channels, <span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(mla_channels, mla_channels, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                                    bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(mla_channels, mla_channels, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                                    bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p4 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(mla_channels, mla_channels, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                                    bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())
        self<span style="color:#f92672">.</span>mla_p5 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(nn<span style="color:#f92672">.</span>Conv2d(mla_channels, mla_channels, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                                    bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>), build_norm_layer(norm_cfg, mla_channels)[<span style="color:#ae81ff">1</span>], nn<span style="color:#f92672">.</span>ReLU())

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">to_2D</span>(self, x):
        n, hw, c <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>shape
        h <span style="color:#f92672">=</span> w <span style="color:#f92672">=</span> int(math<span style="color:#f92672">.</span>sqrt(hw))
        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>reshape(n, c, h, w)
        <span style="color:#66d9ef">return</span> x

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, res2, res3, res4, res5):
        <span style="color:#75715e">#reshape</span>
        res2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>to_2D(res2)
        res3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>to_2D(res3)
        res4 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>to_2D(res4)
        res5 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>to_2D(res5)

        <span style="color:#75715e">#1×1卷积</span>
        mla_p5_1x1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p5_1x1(res5)
        mla_p4_1x1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p4_1x1(res4)
        mla_p3_1x1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p3_1x1(res3)
        mla_p2_1x1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p2_1x1(res2)

        <span style="color:#75715e">#下层特征图与上层特征图相加</span>
        mla_p4_plus <span style="color:#f92672">=</span> mla_p5_1x1 <span style="color:#f92672">+</span> mla_p4_1x1
        mla_p3_plus <span style="color:#f92672">=</span> mla_p4_plus <span style="color:#f92672">+</span> mla_p3_1x1
        mla_p2_plus <span style="color:#f92672">=</span> mla_p3_plus <span style="color:#f92672">+</span> mla_p2_1x1

        <span style="color:#75715e">#3×3卷积</span>
        mla_p5 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p5(mla_p5_1x1)
        mla_p4 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p4(mla_p4_plus)
        mla_p3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p3(mla_p3_plus)
        mla_p2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mla_p2(mla_p2_plus)

        <span style="color:#66d9ef">return</span> mla_p2, mla_p3, mla_p4, mla_p5
</code></pre></div><h2 id="encoder">Encoder</h2>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
          <div class="post-comments">
            <div id="disqus_thread"></div>
<script>
  window.addEventListener("load", () => {
    (function() {
      
      var d = document,
        s = d.createElement("script");
      s.src = "https://joway.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  });
</script>
<noscript
  >Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript"
    >comments powered by Disqus.</a
  ></noscript
>

          </div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  

<script>
  
  
    
    
  
</script>

  

</body>

</html>